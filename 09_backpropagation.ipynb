{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35618caa",
   "metadata": {},
   "source": [
    "# Chapter 9: Backpropagation\n",
    "\n",
    "Start with a simplified forward pass with just one neuron.\n",
    "\n",
    "Let’s backpropagate the ReLU function for a single neuron, then intend to minimize the output for this single neuron as a practice to show how we can leverage the chain rule with derivatives and partial derivatives.\n",
    "\n",
    "We will start by <b>minimizing this more basic output</b> before jumping to the full network and overall loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b28f55da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.0\n"
     ]
    }
   ],
   "source": [
    "x = [1.0, -2.0, 3.0] # input values\n",
    "w = [-3.0, -1.0, 2.0] # weights\n",
    "b = 1.0 # bias\n",
    "\n",
    "xw0 = x[0] * w[0]\n",
    "print(xw0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df959429",
   "metadata": {},
   "source": [
    "<center><img src='./image/9-1.png' style='width: 70%'/><font color='gray'><i>The first input and weight multiplication.</i></font></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f76e5102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.0 2.0 6.0\n"
     ]
    }
   ],
   "source": [
    "xw1 = x[1] * w[1]\n",
    "xw2 = x[2] * w[2]\n",
    "\n",
    "print(xw0, xw1, xw2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdfb5fe",
   "metadata": {},
   "source": [
    "<center><img src='./image/9-2.png' style='width: 70%'/><font color='gray'><i>Input and weight multiplication of all of the inputs.</i></font></center>\n",
    "\n",
    "Perform a sum of all weighted inputs with a bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "781f8435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\n"
     ]
    }
   ],
   "source": [
    "# Adding weighted inputs and a bias\n",
    "z = xw0 + xw1 + xw2 + b\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8b7973",
   "metadata": {},
   "source": [
    "<center><img src='./image/9-3.png' style='width: 70%'/><font color='gray'><i>Weighted inputs and bias addition.</i></font></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93b0fe24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\n"
     ]
    }
   ],
   "source": [
    "# ReLU activation function\n",
    "y = max(z, 0)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e897955",
   "metadata": {},
   "source": [
    "<center><img src='./image/9-4.png' style='width: 70%'/><font color='gray'><i>ReLU activation applied to the neuron output.</i></font></center>\n",
    "\n",
    "This is the full forward pass through a single neuron and a ReLU activation function.\n",
    "\n",
    "Let’s treat all of these chained functions as one big function which takes input values ($x$), weights ($w$), and bias ($b$), as inputs, and outputs ($y$).\n",
    "\n",
    "This big function consists of <b>3 chained functions</b> in total: a multiplication of input values and weights, a sum of these values and bias, as well as a $max$ function as the ReLU activation.\n",
    "\n",
    "\n",
    "## 9.1. Derivative of activation function\n",
    "\n",
    "Backpropagate our gradients by calculating derivatives and partial derivatives w.r.t each of our parameters and inputs.\n",
    "\n",
    "The big function in the context of our neural network, can be loosely interpreted as:\n",
    "\n",
    "$$\n",
    "\\text{ReLU} \\Big( \\sum[ \\ \\text{input} \\cdot \\text{weights} \\ ] + \\text{bias} \\Big)\n",
    "$$\n",
    "\n",
    "Or in the form that matches code more precisely as:\n",
    "\n",
    "$$\n",
    "\\text{ReLU} \\Big( x_0 w_0 + x_1 w_1 + x_2 w_2 + b  \\Big)\n",
    "$$\n",
    "\n",
    "Rewrite the function to the form that will allow us to determine how to calculate the derivatives more easily:\n",
    "\n",
    "$$\n",
    "y = \\text{ReLU} \\Big( sum \\big( mul(x_0 , w_0 ), mul(x_1 , w_1 ), mul(x_2 , w_2 ), b \\big) \\Big)\n",
    "$$\n",
    "\n",
    "Calculate the partial derivative with respect to $w_0$.\n",
    "\n",
    "$$\n",
    "\\frac{∂}{∂x_0} \\bigg[ \\text{ReLU} \\Big( sum \\big( mul(x_0 , w_0 ), mul(x_1 , w_1 ), mul(x_2 , w_2 ), b \\big) \\Big)  \\bigg]\n",
    "$$\n",
    "\n",
    "The derivative with respect to the layer’s inputs is not used to update any parameters. It is used to chain to another layer.\n",
    "\n",
    "We can repeat this to calculate all of the other remaining impacts.\n",
    "\n",
    "We want to know the impact of a given weight or bias on the loss. Thus, we have to calculate the derivative of the loss function and apply the chain rule with the derivatives of all activation functions and neurons in all of the consecutive layers.\n",
    "\n",
    "Assume that our neuron receives a gradient of $1$ from the next layer (for demonstration purposes), a value of $1$ won't change the values, that means we can more easily show all of the processes. The color red is used for derivatives.\n",
    "\n",
    "<center><img src='./image/9-5.png' style='width: 70%'/><font color='gray'><i>Initial gradient (received during backpropagation).</i></font></center>\n",
    "\n",
    "Recall the derivative of $ReLU()$ w.r.t its input:\n",
    "\n",
    "$$\n",
    "f(x) = max(x,0) \\quad \\to \\quad \\frac{d}{dx} f(x) = 1 (x>0)\n",
    "$$\n",
    "\n",
    "The input value to the $ReLU$ function is $6$, so the derivative equals $1$.\n",
    "\n",
    "We have to use the chain rule and multiply this derivative with the derivative received from the next layer (which is 1 for the purpose of this example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bce3fe4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Forward pass\n",
    "x = [1.0, -2.0, 3.0] # input values\n",
    "w = [-3.0, -1.0, 2.0] # weights\n",
    "b = 1.0 # bias\n",
    "\n",
    "# Multiplying inputs by weights\n",
    "xw0 = x[0] * w[0]\n",
    "xw1 = x[1] * w[1]\n",
    "xw2 = x[2] * w[2]\n",
    "\n",
    "# Adding weighted inputs and a bias\n",
    "z = xw0 + xw1 + xw2 + b\n",
    "\n",
    "# ReLU activation function\n",
    "y = max(z, 0)\n",
    "\n",
    "# Backward pass\n",
    "# The derivative from the next layer\n",
    "dvalue = 1.0\n",
    "\n",
    "# Derivative of ReLU and the chain rule\n",
    "drelu_dz = dvalue * (1. if z > 0 else 0.)\n",
    "print(drelu_dz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb864c3",
   "metadata": {},
   "source": [
    "<center><img src='./image/9-6.png' style='width: 70%'/><font color='gray'><i>Derivative of the $ReLU$ function and chain rule.</i></font></center>\n",
    "\n",
    "This results with the derivative of 1 :\n",
    "\n",
    "<center><img src='./image/9-7.png' style='width: 70%'/><font color='gray'><i>ReLU and chain rule gradient.</i></font></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2bec78",
   "metadata": {},
   "source": [
    "## 9.2. Derivative of a sum of the weighted inputs and bias\n",
    "\n",
    "Moving backward through our neural network, a sum of the weighted inputs and bias comes immediately before we perform the activation function.\n",
    "\n",
    "Thus, we must calculate the partial derivative of the sum function, then, using the chain rule, multiply this by the partial derivative of the subsequent, outer, function, which is $ReLU$.\n",
    "\n",
    "Recall the partial derivative of the sum operation is always 1:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "f(x,y) = x+y \\quad \\to \\quad & \\frac{∂}{∂x} f(x,y) = 1\\\\\n",
    "& \\frac{∂}{∂y} f(x,y) = 1 \\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c276ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0 1.0 1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "# Forward pass\n",
    "x = [1.0, -2.0, 3.0] # input values\n",
    "w = [-3.0, -1.0, 2.0] # weights\n",
    "b = 1.0 # bias\n",
    "\n",
    "# Multiplying inputs by weights\n",
    "xw0 = x[0] * w[0]\n",
    "xw1 = x[1] * w[1]\n",
    "xw2 = x[2] * w[2]\n",
    "\n",
    "# Adding weighted inputs and a bias\n",
    "z = xw0 + xw1 + xw2 + b\n",
    "\n",
    "# ReLU activation function\n",
    "y = max(z, 0)\n",
    "\n",
    "# Backward pass\n",
    "# The derivative from the next layer\n",
    "dvalue = 1.0\n",
    "\n",
    "# Derivative of ReLU and the chain rule\n",
    "drelu_dz = dvalue * (1. if z > 0 else 0.)\n",
    "print(drelu_dz)\n",
    "\n",
    "# Partial derivatives of the multiplication, the chain rule\n",
    "dsum_dxw0 = 1\n",
    "dsum_dxw1 = 1\n",
    "dsum_dxw2 = 1\n",
    "dsum_db = 1\n",
    "drelu_dxw0 = drelu_dz * dsum_dxw0\n",
    "drelu_dxw1 = drelu_dz * dsum_dxw1\n",
    "drelu_dxw2 = drelu_dz * dsum_dxw2\n",
    "drelu_db = drelu_dz * dsum_db\n",
    "\n",
    "print(drelu_dxw0, drelu_dxw1, drelu_dxw2, drelu_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a7db60",
   "metadata": {},
   "source": [
    "<center><img src='./image/9-8.png' style='width: 70%'/><font color='gray'><i>Partial derivative of the sum function w.r.t. the first weighted input.</i></font></center>\n",
    "\n",
    "This results with a partial derivative of 1 again:\n",
    "\n",
    "<center><img src='./image/9-9.png' style='width: 70%'/><font color='gray'><i>The sum and chain rule gradient for the first weighted input.</i></font></center>\n",
    "\n",
    "Perform the same operation with the next weighted input:\n",
    "\n",
    "<center><img src='./image/9-10.png' style='width: 70%'/><font color='gray'><i>Partial derivative of the sum function w.r.t. the second weighted input.</i></font></center>\n",
    "\n",
    "Which results with the next calculated partial derivative:\n",
    "\n",
    "<center><img src='./image/9-11.png' style='width: 70%'/><font color='gray'><i>The sum and chain rule gradient (for the second weighted input).</i></font></center>\n",
    "\n",
    "And the last weighted input:\n",
    "\n",
    "<center><img src='./image/9-12.png' style='width: 70%'/><font color='gray'><i>Partial derivative of the sum function w.r.t. the third weighted input.</i></font></center>\n",
    "\n",
    "<center><img src='./image/9-13.png' style='width: 70%'/><font color='gray'><i>The sum and chain rule gradient (for the third weighted input).</i></font></center>\n",
    "\n",
    "Then the bias:\n",
    "\n",
    "<center><img src='./image/9-14.png' style='width: 70%'/><font color='gray'><i>Partial derivative of the sum function w.r.t. the bias.</i></font></center>\n",
    "\n",
    "<center><img src='./image/9-15.png' style='width: 70%'/><font color='gray'><i>The sum and chain rule gradient (for the bias).</i></font></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdd73a2",
   "metadata": {},
   "source": [
    "## 9.3. Derivative of the multiplication of weights and inputs\n",
    "\n",
    "The derivative for a product is whatever the input is being multiplied by.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "f(x,y) = x \\cdot y \\quad \\to \\quad & \\frac{∂}{∂x} f(x,y) = y \\\\\n",
    "& \\frac{∂}{∂y} f(x,y) = x \\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "246f2955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.0 1.0 -1.0 -2.0 2.0 3.0\n"
     ]
    }
   ],
   "source": [
    "# Partial derivatives of the multiplication, the chain rule\n",
    "dmul_dx0 = w[0]\n",
    "dmul_dx1 = w[1]\n",
    "dmul_dx2 = w[2]\n",
    "dmul_dw0 = x[0]\n",
    "dmul_dw1 = x[1]\n",
    "dmul_dw2 = x[2]\n",
    "drelu_dx0 = drelu_dxw0 * dmul_dx0\n",
    "drelu_dw0 = drelu_dxw0 * dmul_dw0\n",
    "drelu_dx1 = drelu_dxw1 * dmul_dx1\n",
    "drelu_dw1 = drelu_dxw1 * dmul_dw1\n",
    "drelu_dx2 = drelu_dxw2 * dmul_dx2\n",
    "drelu_dw2 = drelu_dxw2 * dmul_dw2\n",
    "\n",
    "print(drelu_dx0, drelu_dw0, drelu_dx1, drelu_dw1, drelu_dx2, drelu_dw2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30d9543",
   "metadata": {},
   "source": [
    "<center><img src='./image/9-16.png' style='width: 70%'/><font color='gray'><i>Partial derivative of the multiplication function w.r.t. the first input.</i></font></center>\n",
    "\n",
    "<center><img src='./image/9-17.png' style='width: 70%'/><font color='gray'><i>The multiplication and chain rule gradient (for the first input).</i></font></center>\n",
    "\n",
    "The complete set of the activated neuron’s partial derivatives with respect to the inputs, weights and a bias.\n",
    "\n",
    "<center><img src='./image/9-18.png' style='width: 70%'/><font color='gray'><i>Complete backpropagation graph.</i></font></center>\n",
    "\n",
    "Recall the equation from the beginning:\n",
    "\n",
    "$$\n",
    "\\frac{∂}{∂x_0} \\bigg[ \\text{ReLU} \\Big( sum \\big( mul(x_0 , w_0 ), mul(x_1 , w_1 ), mul(x_2 , w_2 ), b \\big) \\Big)  \\bigg]\n",
    "= \\frac{d \\text{ReLU} }{d sum()} \\cdot \\frac{∂ sum() }{∂ mul(x_0 , w_0 )} \\cdot \\frac{∂ mul(x_0 , w_0 )}{∂x_0}\n",
    "$$\n",
    "\n",
    "The partial derivative of a neuron’s function, with respect to the weight, is the input related to this weight, and, with respect to the input, is the related weight. The partial derivative of the neuron’s function with respect to the bias is always 1.\n",
    "\n",
    "\n",
    "## 9.4. Update weight and bias to decrease output\n",
    "\n",
    "All partial derivatives above combined into a vector, make up our gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a3fd683",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = [drelu_dx0, drelu_dx1, drelu_dx2] # gradients on inputs\n",
    "dw = [drelu_dw0, drelu_dw1, drelu_dw2] # gradients on weights\n",
    "db = drelu_db # gradient on bias...just 1 bias here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff74a24",
   "metadata": {},
   "source": [
    "For this single neuron example, we won't need our $dx$.\n",
    "\n",
    "We will apply these gradients to the weights to hopefully minimize the output.\n",
    "\n",
    "We apply a negative fraction to this gradient to decrease the final output value, as the gradient shows the direction of the steepest ascent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "431c089f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.0, -1.0, 2.0] 1.0\n"
     ]
    }
   ],
   "source": [
    "print(w, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39725f35",
   "metadata": {},
   "source": [
    "Apply a fraction of the gradients to these values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19b25533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.001, -0.998, 1.997] 0.999\n"
     ]
    }
   ],
   "source": [
    "w[0] += -0.001 * dw[0]\n",
    "w[1] += -0.001 * dw[1]\n",
    "w[2] += -0.001 * dw[2]\n",
    "b += -0.001 * db\n",
    "print(w, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412137f7",
   "metadata": {},
   "source": [
    "We slightly changed the weights and bias in such a way to decrease the output intelligently.\n",
    "\n",
    "Do another forward pass to see the effects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b01d73e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.985\n"
     ]
    }
   ],
   "source": [
    "# Multiplying inputs by weights\n",
    "xw0 = x[0] * w[0]\n",
    "xw1 = x[1] * w[1]\n",
    "xw2 = x[2] * w[2]\n",
    "\n",
    "# Adding\n",
    "z = xw0 + xw1 + xw2 + b\n",
    "\n",
    "# ReLU activation function\n",
    "y = max(z, 0)\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dcfaee",
   "metadata": {},
   "source": [
    "We've successfully decreased this neuron's output from $6.000$ to $5.985$.\n",
    "\n",
    "It does not make sense to decrease the neuron's output in a real neural network. We do this as a simpler exercise.\n",
    "\n",
    "We want to decrease the loss value, which is the last calculation in the chain of calculations during the forward pass, and it's the first one to calculate the gradient during the backpropagation.\n",
    "\n",
    "## 9.5. List of samples and a layer of neurons\n",
    "\n",
    "### A singular sample\n",
    "\n",
    "A single neuron of the current layer connects to all of them — they all receive the output of this neuron.\n",
    "\n",
    "What happen during backpropagation?\n",
    "\n",
    "Each neuron from the next layer will return a partial derivative of its function w.r.t all of its inputs.\n",
    "\n",
    "The neuron in the current layer will receive a vector consisting of these derivatives.\n",
    "\n",
    "To continue backpropagation, we need to sum this vector to be a singular value for a singular neuron.\n",
    "\n",
    "For a layer of neurons, it'll be a list of these vectors, or a 2D array.\n",
    "\n",
    "To apply the chain rule, we need to multiply them by the gradient from the subsequent function.\n",
    "\n",
    "We should perform a sum along the inputs - the first input to all of the neurons, the second input, and so on. So we have to sum columns.\n",
    "\n",
    "The array of partial derivatives w.r.t all of the inputs equals the array of weights.\n",
    "\n",
    "Since the array is transposed, we need to sum its rows instead of columns.\n",
    "\n",
    "Then we calculate the gradient for the next layer in backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ecb92a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.44 -0.38 -0.07  1.37]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Passed in gradient from the next layer\n",
    "# for the purpose of this example we're going to use\n",
    "# a vector of 1s\n",
    "dvalues = np.array([[1., 1., 1.]])\n",
    "\n",
    "# We have 3 sets of weights - one set for each neuron\n",
    "# we have 4 inputs, thus 4 weights\n",
    "# recall that we keep weights transposed\n",
    "weights = np.array([[0.2, 0.8, -0.5, 1],\n",
    "                    [0.5, -0.91 , 0.26, -0.5],\n",
    "                    [-0.26, -0.27 , 0.17, 0.87]]).T\n",
    "\n",
    "# sum weights of given input\n",
    "# and multiply by the passed in gradient for this neuron\n",
    "dx0 = sum(weights[0] * dvalues[0])\n",
    "dx1 = sum(weights[1] * dvalues[0])\n",
    "dx2 = sum(weights[2] * dvalues[0])\n",
    "dx3 = sum(weights[3] * dvalues[0])\n",
    "\n",
    "# the gradient of the neuron function with respect to inputsm\n",
    "dinputs = np.array([dx0, dx1, dx2, dx3])\n",
    "\n",
    "print(dinputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88033c9f",
   "metadata": {},
   "source": [
    "We can achieve the same result by using the `np.dot` function. \n",
    "\n",
    "Recall, we have one partial derivative for each neuron and multiply it by the neuron’s partial derivative with respect to its input.\n",
    "\n",
    "Then, multiply each of these gradients with each of the partial derivatives that are related to this neuron’s inputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9b617a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.44 -0.38 -0.07  1.37]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Passed in gradient from the next layer\n",
    "# for the purpose of this example we're going to use\n",
    "# a vector of 1s\n",
    "dvalues = np.array([[1., 1., 1.]])\n",
    "\n",
    "# We have 3 sets of weights - one set for each neuron\n",
    "# we have 4 inputs, thus 4 weights\n",
    "# recall that we keep weights transposed\n",
    "weights = np.array([[0.2, 0.8, -0.5, 1],\n",
    "                    [0.5, -0.91, 0.26, -0.5 ],\n",
    "                    [-0.26, -0.27, 0.17, 0.87 ]]).T\n",
    "\n",
    "# sum weights of given input\n",
    "# and multiply by the passed in gradient for this neuron\n",
    "dinputs = np.dot(dvalues[ 0 ], weights.T)\n",
    "\n",
    "print (dinputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2367bb70",
   "metadata": {},
   "source": [
    "### A batch of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af991f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.44 -0.38 -0.07  0.5 ]\n",
      " [ 0.88 -0.76 -0.14  1.  ]\n",
      " [ 1.32 -1.14 -0.21  1.5 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Passed in gradient from the next layer\n",
    "# for the purpose of this example we're going to use\n",
    "# an array of an incremental gradient values\n",
    "dvalues = np.array([[1., 1., 1.],\n",
    "                    [2., 2., 2.],\n",
    "                    [3., 3., 3.]])\n",
    "\n",
    "# We have 3 sets of weights - one set for each neuron\n",
    "# we have 4 inputs, thus 4 weights\n",
    "# recall that we keep weights transposed\n",
    "weights = np.array([[0.2, 0.8, -0.5, 1],\n",
    "                    [0.5, -0.91, 0.26, -0.5],\n",
    "                    [-0.26, -0.27, 0.17, 0]]).T\n",
    "\n",
    "# sum weights of given input\n",
    "# and multiply by the passed in gradient for this neuron\n",
    "dinputs = np.dot(dvalues, weights.T)\n",
    "\n",
    "print (dinputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8574b3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5  0.5  0.5]\n",
      " [20.1 20.1 20.1]\n",
      " [10.9 10.9 10.9]\n",
      " [ 4.1  4.1  4.1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Passed in gradient from the next layer for the purpose of this example \n",
    "# We're going to use an array of an incremental gradient values\n",
    "dvalues = np.array([[1., 1., 1.],\n",
    "                    [2., 2., 2.],\n",
    "                    [3., 3., 3.]])\n",
    "\n",
    "# We have 3 sets of inputs - samples\n",
    "inputs = np.array([[1, 2, 3, 2.5],\n",
    "                [2., 5., -1., 2],\n",
    "                [-1.5, 2.7, 3.3, -0.8]])\n",
    "\n",
    "# Sum weights of given input and multiply by the passed in gradient for this neuron\n",
    "dweights = np.dot(inputs.T, dvalues)\n",
    "\n",
    "print(dweights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92599710",
   "metadata": {},
   "source": [
    "For the biases and derivatives with respect to them, the derivatives come from the sum operation and always equal 1, multiplied by the incoming gradients to apply the chain rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7593dcbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6. 6. 6.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Passed in gradient from the next layer for the purpose of this example\n",
    "# we're going to use an array of an incremental gradient values\n",
    "dvalues = np.array([[1., 1., 1.],\n",
    "                    [2., 2., 2.],\n",
    "                    [3., 3., 3.]])\n",
    "\n",
    "# One bias for each neuron biases are the row vector with a shape (1, neurons)\n",
    "biases = np.array([[2, 3, 0.5]])\n",
    "\n",
    "# dbiases - sum values, do this over samples (first axis), keepdims\n",
    "# since this by default will produce a plain list - we explained this in the chapter 4\n",
    "dbiases = np.sum(dvalues, axis = 0 , keepdims = True )\n",
    "\n",
    "print(dbiases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d12e4c8",
   "metadata": {},
   "source": [
    "### Derivative of the ReLU function\n",
    "\n",
    "It equals 1 if the input is greater than 0 and 0 otherwise.\n",
    "\n",
    "The layer passes its outputs through the $ReLU()$ activation during the forward pass.\n",
    "\n",
    "For the backward pass, $ReLU()$ receives a gradient of the same shape.\n",
    "\n",
    "The derivative of the ReLU function will form an array of the same shape, filled with 1 when the related input is greater than 0, and 0 otherwise.\n",
    "\n",
    "To apply the chain rule, we need to multiply this array with the gradients of the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29a289f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 0 0]\n",
      " [1 0 0 1]\n",
      " [0 1 1 0]]\n",
      "[[ 1  2  0  0]\n",
      " [ 5  0  0  8]\n",
      " [ 0 10 11  0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example layer output (4 neurons)\n",
    "z = np.array([[1, 2, -3, -4],\n",
    "              [2, -7, -1, 3],\n",
    "              [-1, 2, 5, -1]])\n",
    "\n",
    "dvalues = np.array([[1, 2, 3, 4],\n",
    "                    [5, 6, 7, 8],\n",
    "                    [9, 10, 11, 12]])\n",
    "\n",
    "# ReLU activation's derivative\n",
    "drelu = np.zeros_like(z)\n",
    "drelu[z > 0] = 1\n",
    "print(drelu)\n",
    "\n",
    "# The chain rule\n",
    "drelu *= dvalues\n",
    "\n",
    "print(drelu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcb49f7",
   "metadata": {},
   "source": [
    "We can simplify this operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa15faa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  0  0]\n",
      " [ 5  0  0  8]\n",
      " [ 0 10 11  0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example layer output\n",
    "z = np.array([[1, 2, -3, -4],\n",
    "              [2, -7, -1, 3],\n",
    "              [-1, 2, 5, -1]])\n",
    "\n",
    "dvalues = np.array([[1, 2, 3, 4],\n",
    "                    [5, 6, 7, 8],\n",
    "                    [9, 10, 11, 12]])\n",
    "\n",
    "# ReLU activation's derivative with the chain rule applied\n",
    "drelu = dvalues.copy()    # ensures that we don't modify it during the ReLU derivative calculation.\n",
    "drelu[z <= 0] = 0\n",
    "\n",
    "print(drelu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b632853d",
   "metadata": {},
   "source": [
    "Let’s combine the forward and backward pass of a single neuron with a full layer and batch-based partial derivatives. We’ll minimize ReLU’s output, once again, only for this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5b09f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.1995  0.5035 -0.2605]\n",
      " [ 0.7799 -0.9201 -0.2901]\n",
      " [-0.5109  0.2471  0.1591]\n",
      " [ 0.9959 -0.5001  0.8659]]\n",
      "[[1.994 2.996 0.494]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Passed in gradient from the next layer for the purpose of this example\n",
    "# We're going to use an array of an incremental gradient values\n",
    "dvalues = np.array([[1., 1., 1.],\n",
    "                    [2., 2., 2.],\n",
    "                    [3., 3., 3.]])\n",
    "\n",
    "# We have 3 sets of inputs - samples\n",
    "inputs = np.array([[1, 2, 3, 2.5],\n",
    "                   [2., 5., -1., 2],\n",
    "                   [-1.5, 2.7, 3.3, -0.8]])\n",
    "\n",
    "# We have 3 sets of weights - one set for each neuron\n",
    "# we have 4 inputs, thus 4 weights\n",
    "# recall that we keep weights transposed\n",
    "weights = np.array([[0.2, 0.8, -0.5, 1],\n",
    "                    [0.5, -0.91, 0.26, -0.5],\n",
    "                    [-0.26, -0.27, 0.17, 0.87]]).T\n",
    "\n",
    "# One bias for each neuron\n",
    "# biases are the row vector with a shape (1, neurons)\n",
    "biases = np.array([[2, 3, 0.5]])\n",
    "\n",
    "# Forward pass\n",
    "layer_outputs = np.dot(inputs, weights) + biases # Dense layer\n",
    "relu_outputs = np.maximum(0, layer_outputs) # ReLU activation\n",
    "\n",
    "# Let's optimize and test backpropagation here\n",
    "# ReLU activation - simulates derivative with respect to input values\n",
    "# from next layer passed to current layer during backpropagation\n",
    "drelu = dvalues.copy()\n",
    "drelu[layer_outputs <= 0] = 0\n",
    "\n",
    "# Dense layer\n",
    "# dinputs - multiply by weights\n",
    "dinputs = np.dot(drelu, weights.T)\n",
    "\n",
    "# dweights - multiply by inputs\n",
    "dweights = np.dot(inputs.T, drelu)\n",
    "\n",
    "# dbiases - sum values, do this over samples (first axis), keepdims\n",
    "# since this by default will produce a plain list - we explained this in the chapter 4\n",
    "dbiases = np.sum(drelu, axis = 0 , keepdims = True)\n",
    "\n",
    "# Update parameters\n",
    "weights += - 0.001 * dweights\n",
    "biases += - 0.001 * dbiases\n",
    "\n",
    "print(weights)\n",
    "print(biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072a2903",
   "metadata": {},
   "source": [
    "Update the dense layer and ReLU activation code with a `backward` method (for backpropagation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49da7bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense layer\n",
    "class Layer_Dense :\n",
    "    # Layer initialization\n",
    "    def __init__ (self, inputs, neurons):\n",
    "        self.weights = 0.01 * np.random.randn(inputs, neurons)\n",
    "        self.biases = np.zeros((1, neurons))\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "        # To remember what the inputs were (needed when calculating the partial derivative w.r.t weights during backpropagation)\n",
    "        self.inputs = inputs\n",
    "        \n",
    "    # Backward pass\n",
    "    def backward(self, dvalues):\n",
    "        # Gradients on parameters\n",
    "        self.dweights = np.dot(self.inputs.T, dvalues)\n",
    "        self.dbiases = np.sum(dvalues, axis = 0, keepdims = True)\n",
    "\n",
    "        # Gradient on values\n",
    "        self.dinputs = np.dot(dvalues, self.weights.T)\n",
    "\n",
    "\n",
    "# ReLU activation\n",
    "class Activation_ReLU :\n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "        # Remember input values\n",
    "        self.inputs = inputs\n",
    "        self.output = np.maximum(0, inputs)\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues):\n",
    "        # Since we need to modify the original variable, let's make a copy of the values first\n",
    "        self.dinputs = dvalues.copy()\n",
    "\n",
    "        # Zero gradient where input values were negative\n",
    "        self.dinputs[self.inputs <= 0 ] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c57d53",
   "metadata": {},
   "source": [
    "## 9.6. Categorical Cross-Entropy loss derivative\n",
    "\n",
    "As stated in chapter 5, the Categorical Cross-Entropy loss function's formula is:\n",
    "\n",
    "$$\n",
    "L_i = \\ \\text{log} \\ \\big(  \\hat{y}_{i,k} \\big) \\qquad \\text{where }  k \\text{ is an index of \"true\" probability}\n",
    "$$\n",
    "\n",
    "where $L_i$ denotes sample loss value, $i^{th}$ sample in a set, $k$ - index of the target label (ground-true label), $y$ - target values and $\\hat y$ predicted values.\n",
    "\n",
    "All we need is the output of the Softmax activation function at the index of the correct class.\n",
    "\n",
    "To calculate partial derivatives with respect to each of the inputs, we need an equation that takes all of them as parameters, thus the choice to use the full equation.\n",
    "\n",
    "For the purpose of the derivative calculation, we use the full equation mentioned back in chapter 5:\n",
    "\n",
    "$$\n",
    "L_i = - \\sum_j y_{i,j} \\ \\text{log} \\ \\big(  \\hat{y}_{i,j} \\big)\n",
    "$$\n",
    "\n",
    "where $L_i$ denotes sample loss value, $i^{th}$ sample in a set, $j$ - label/output index, $y$ - target values and $\\hat y$ predicted values.\n",
    "\n",
    "Recall,\n",
    "\n",
    "$$\n",
    "f(x) = \\text{log} \\big( h(x) \\big) \\quad \\to \\quad f'(x) = \\frac{1}{h(x)} \\cdot h'(x)\\\\\n",
    "f(x) = \\text{log} (x) \\quad \\to \\quad \\frac{d}{dx} f(x) = \\frac{d}{dx} \\text{log} (x) =   \\frac{1}{x} \\cdot \\frac{d}{dx} x = \\frac{1}{x} \\cdot 1 = \\frac{1}{x}\n",
    "$$\n",
    "\n",
    "First, let’s define the gradient equation as the partial derivative of the loss function w.r.t each of its inputs.\n",
    "\n",
    "$$\n",
    "\\frac{∂ L_i}{∂ \\hat{y}_{i,j}} = \\frac{∂ }{∂ \\hat{y}_{i,j}} \\Big[  - \\sum_j y_{i,j} \\ \\text{log} \\ \\big(  \\hat{y}_{i,j} \\big)  \\Big] =   - \\sum_j y_{i,j} \\cdot \\frac{∂ }{∂ \\hat{y}_{i,j}}  \\text{log} \\big(  \\hat{y}_{i,j} \\big)  =   - \\sum_j y_{i,j} \\cdot \\frac{1}{\\hat{y}_{i,j}} \\cdot \\frac{∂ }{∂ \\hat{y}_{i,j}}  \\hat{y}_{i,j}  =   - \\sum_j y_{i,j} \\cdot \\frac{1}{\\hat{y}_{i,j}} \\cdot 1  =  - \\sum_j \\frac{y_{i,j}}{\\hat{y}_{i,j}}  =  - \\frac{y_{i,j}}{\\hat{y}_{i,j}}\n",
    "$$\n",
    "\n",
    "The derivative of this loss function with respect to its inputs (predicted values at the $i^{th}$ sample, since we are interested in a gradient with respect to the predicted values) equals the negative ground-truth vector, divided by the vector of the predicted values (which is also the output vector of the softmax function).\n",
    "\n",
    "\n",
    "## 9.7. Categorical Cross-Entropy loss derivative code implementation\n",
    "\n",
    "Add a backward method to the `Loss_CategoricalCrossentropy` class, and pass the array of predictions and the array of true values into it and calculate the negated division of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e71c8050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common loss class\n",
    "class Loss :\n",
    "    \n",
    "    # Calculates the data and regularization losses given model output and ground truth values\n",
    "    def calculate ( self , output , y ):\n",
    "        \n",
    "        # Calculate sample losses\n",
    "        sample_losses = self.forward(output, y)\n",
    "        \n",
    "        # Calculate mean loss\n",
    "        data_loss = np.mean(sample_losses)\n",
    "        \n",
    "        # Return loss\n",
    "        \n",
    "        return data_loss\n",
    "\n",
    "    \n",
    "# Cross-entropy loss\n",
    "class Loss_CategoricalCrossentropy(Loss):\n",
    "    \n",
    "    # Forward pass\n",
    "    def forward(self, y_pred, y_true):\n",
    "        \n",
    "        # Number of samples in a batch\n",
    "        samples = len(y_pred)\n",
    "        \n",
    "        # Clip data to prevent division by 0\n",
    "        # Clip both sides to not drag mean towards any value\n",
    "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "        \n",
    "        # Probabilities for target values - only if categorical labels\n",
    "        if len(y_true.shape) == 1:\n",
    "            correct_confidences = y_pred_clipped[ range(samples), y_true]\n",
    "        \n",
    "        # Mask values - only for one-hot encoded labels\n",
    "        elif len(y_true.shape) == 2:\n",
    "            correct_confidences = np.sum( y_pred_clipped*y_true, axis=1)\n",
    "        \n",
    "        # Losses\n",
    "        negative_log_likelihoods = -np.log(correct_confidences)\n",
    "        \n",
    "        return negative_log_likelihoods\n",
    "\n",
    "    # Backward pass\n",
    "    def backward (self, dvalues, y_true):\n",
    "\n",
    "        # Number of samples\n",
    "        samples = len(dvalues)\n",
    "\n",
    "        # Number of labels in every sample\n",
    "        # We'll use the first sample to count them\n",
    "        labels = len(dvalues[0])\n",
    "\n",
    "        # If labels are sparse, turn them into one-hot vector\n",
    "        if len(y_true.shape) == 1 :\n",
    "            y_true = np.eye(labels)[y_true]\n",
    "\n",
    "        # Calculate gradient\n",
    "        self.dinputs = -y_true/dvalues\n",
    "\n",
    "        # Normalize gradient\n",
    "        self.dinputs = self.dinputs/samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02b4cc4",
   "metadata": {},
   "source": [
    "Optimizers sum all of the gradients related to each weight and bias before multiplying them by the learning rate (or some other factor). This means that the more samples we have in a dataset, the more gradient sets we’ll receive at this step, and the bigger this sum will become. As a consequence, we’ll have to adjust the learning rate according to each set of samples.\n",
    "\n",
    "To solve this problem, we can divide all of the gradients by the number of samples. A sum of elements divided by a count of them is their mean value (the optimizer will perform the sum). Thus, we will effectively normalize the gradients and make their sum’s magnitude invariant to the number of samples.\n",
    "\n",
    "\n",
    "## 9.8. Softmax activation derivative\n",
    "\n",
    "The partial derivative of the Softmax function is a bit more complicated task than the derivative of the Categorical Cross-Entropy loss.\n",
    "\n",
    "Recall, the equation of the Softmax activation function and define the derivative:\n",
    "\n",
    "$$\n",
    "S_{i,j} = \\frac{e^{z_{i,j}}}{\\sum_{l=1}^{L} e^{z_{i,l}}} \\quad \\to \\quad \\frac{∂ S_{i,j}}{∂z_{i,k}} = \\frac{∂ \\frac{e^{z_{i,j}}}{\\sum_{l=1}^{L} e^{z_{i,l}}}}{∂z_{i,k}}\n",
    "$$\n",
    "\n",
    "where $S_{i,j}$ denotes $j^{th}$ Softmax’s output of $i^{th}$ sample, $z$ - input array which is a list of input vectors (output vectors from the previous layer), $z_{i,j}$ - $j^{th}$ Softmax’s input of $i^{th}$ sample, $L$ - number of inputs, $z_{i,k}$ - $k^{th}$ Softmax’s input of $i^{th}$ sample.\n",
    "\n",
    "As described in chapter 4, the Softmax function equals the exponential input divided by the sum of all exponentiated inputs.\n",
    "\n",
    "Each input to the Softmax impacts each of the outputs, and we need to calculate the partial derivative of each output with respect to each input.\n",
    "\n",
    "If we calculate the impact of one list on the other list, we’ll receive a matrix of values as a result.\n",
    "\n",
    "It is the Jacobian matrix of the vectors.\n",
    "\n",
    "Recall, the derivative of the division operation:\n",
    "\n",
    "$$\n",
    "f(x) = \\frac{g(x)}{h(x)} \\quad \\to \\quad f'(x) = \\frac{ g'(x) \\cdot h(x) - g(x) \\cdot h'(x)}{\\big[ h(x) \\big]^2}\n",
    "$$\n",
    "\n",
    "Thus,\n",
    "\n",
    "$$\n",
    "\\frac{∂ S_{i,j}}{∂z_{i.k}} = \\frac{∂ \\frac{e^{z_{i,j}}}{\\sum_{l=1}^{L} e^{z_{i,l}}}}{∂z_{i.k}} \n",
    "= \\frac{ \\frac{∂}{∂z_{i,k}} e^{z_i,j} \\cdot \\sum_{l=1}^{L} e^{z_{i,l}} \\ - \\   e^{z_i,j} \\cdot \\frac{∂}{∂z_{i,k}} \\sum_{l=1}^{L} e^{z_{i,l}} }{ \\big[ \\sum_{l=1}^{L} e^{z_{i,l}} \\big]^2}\n",
    "$$\n",
    "\n",
    "Recall,\n",
    "\n",
    "$$\n",
    "\\frac{d}{dn} e^n = e^n \\cdot \\frac{d}{dn} n = e^n \\cdot 1 = e^n\n",
    "$$\n",
    "\n",
    "The RHS of the numerator:\n",
    "\n",
    "$$\n",
    "\\frac{∂}{∂z_{i,k}} \\sum_{l=1}^{L} e^{z_{i,l}}\n",
    "$$\n",
    "\n",
    "The range $1 \\cdot \\cdot \\cdot L$ contains $k$ ($k$ is one of the indices from this range) exactly once and then, in this case, the derivative is going to equal $e$ to the power of the $z_{i,k}$ (as $j$ equals $k$) and $0$ otherwise (when $j$ does not equal $k$ as $z_{i,l}$ won’t contain $z_{i,k}$ and will be treated as a constant — The derivative of the constant equals $0$):\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{∂}{∂z_{i,k}} \\sum_{l=1}^{L} e^{z_{i,l}} & = \\frac{∂}{∂z_{i,k}} e^{z_{i, 1}} + \\frac{∂}{∂z_{i,k}} e^{z_{i, 2}}  + \\cdots + \\frac{∂}{∂z_{i,k}} e^{z_{i, k}} + \\cdots + \\frac{∂}{∂z_{i,k}} e^{z_{i, L-1}} + \\frac{∂}{∂z_{i,k}} e^{z_{i, L}}\\\\\n",
    "& = 0 + 0 + \\cdots + e^{z_{i ,k} } + \\cdots + 0 + 0 = e^{z_{i ,k} } \\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "The LHS of the numerator:\n",
    "\n",
    "$$\n",
    "\\frac{∂}{∂z_{i,k}}  e^{z_{i,j}}\n",
    "$$\n",
    "\n",
    "It can become either $0$ if $j \\neq k$ or $e$ to the power of the $z_{i, k}$ if $j=k$.\n",
    "\n",
    "<b>Starting from this step, we need to calculate the derivatives separately for both cases.</b>\n",
    "\n",
    "In the case of $i=j$:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{∂ S_{i, \\ j}}{∂z_{i, \\ k}} & = \\frac{ e^{z_{i, \\ j}} \\cdot \\sum_{l=1}^{L} e^{z_{i, \\ l}} - e^{z_{i, \\ j}} \\cdot e^{z_{i, \\ k}}}{\\big[ \\sum_{l=1}^{L} e^{z_{i, \\ l}} \\big]^2} = \\frac{e^{z_{i, \\ j}} \\cdot \\big(\\sum_{l=1}^{L} e^{z_{i, \\ l}} - e^{z_{i, \\ k}}\\big)}{\\sum_{l=1}^{L} e^{z_{i, \\ l}} \\cdot  \\sum_{l=1}^{L} e^{z_{i, \\ l}} } \\\\\n",
    "& = \\frac{e^{z_{i, \\ j}} }{\\sum_{l=1}^{L} e^{z_{i, \\ l}}}  \\cdot \\frac{\\sum_{l=1}^{L} e^{z_{i, \\ l}} - e^{z_{i, \\ k}}}{\\sum_{l=1}^{L} e^{z_{i, \\ l}}} = \\frac{e^{z_{i, \\ j}}}{\\sum_{l=1}^{L} e^{z_{i, \\ l}}} \\cdot \\bigg(\\frac{\\sum_{l=1}^{L} e^{z_{i, \\ l}}}{\\sum_{l=1}^{L} e^{z_{i, \\ l}}} - \\frac{e^{z_{i, \\ k}}}{\\sum_{l=1}^{L} e^{z_{i, \\ l}}} \\bigg) = S_{i, \\ j} \\cdot ( 1 - S_{i, \\ k}) \\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "In the case of $i \\neq j$:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{∂ S_{i,j}}{∂z_{i,k}} & = \\frac{ 0 \\cdot \\sum_{l=1}^{L} e^{z_{i, \\ l}} \\ - \\ e^{z_{i, \\ j}} \\cdot e^{z_{i, \\ k}}  }{ \\big[ \\sum_{l=1}^{L} e^{z_{i, \\ l}} \\big]^2} = \\frac{  - \\ e^{z_{i, \\ j}} \\cdot e^{z_{i, \\ k}}  }{ \\big[ \\sum_{l=1}^{L} e^{z_{i, \\ l}} \\big]^2} = \\frac{  - \\ e^{z_{i, \\ j}} \\cdot e^{z_{i, \\ k}}  }{  \\sum_{l=1}^{L} e^{z_{i, \\ l}} \\cdot \\sum_{l=1}^{L} e^{z_{i, \\ l}} } = - \\frac{  \\ e^{z_{i, \\ j}}  }{  \\sum_{l=1}^{L} e^{z_{i, \\ l}} }  \\cdot \\frac{ e^{z_{i, \\ k}}  }{ \\sum_{l=1}^{L} e^{z_{i, \\ l}} } = - S_{i, \\ j } \\cdot S_{i, \\ k }\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "As a summary, the solution of the derivative of the Softmax function with respect to its inputs is:\n",
    "\n",
    "$$\n",
    "\\frac{∂ S_{i,j}}{∂z_{i, \\ k}}  =\n",
    "\\begin{cases}\n",
    "S_{i, \\ j} \\cdot ( 1 - S_{i, \\ k})  , & j = k \\\\\n",
    "- S_{i, \\ j } \\cdot S_{i, \\ k }, & j ≠ k\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Now, we have 2 separate equations to code and use in different cases, which isn't very convenient for the speed of calculations.\n",
    "\n",
    "We rewrite:\n",
    "\n",
    "$$\n",
    "\\frac{∂ S_{i, \\ j}}{∂z_{i, \\ k}}  =\n",
    "\\begin{cases}\n",
    "S_{i, \\ j} \\cdot ( 1 - S_{i, \\ k })  , & j = k \\\\\n",
    "S_{i, \\ j} \\cdot ( 0 - S_{i, \\ k }) ,  & j ≠ k\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "There exists Kronecker delta function whose equation is:\n",
    "\n",
    "$$\n",
    "\\delta _{i, \\ j}  =\n",
    "\\begin{cases}\n",
    "1 , & i = j \\\\\n",
    "0 , & i ≠ j\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Apply it to simplify the equation further:\n",
    "\n",
    "$$\n",
    "\\frac{∂ S_{i, \\ j}}{∂z_{i, \\ k}}  = S_{i, \\ j} \\cdot ( \\delta _{j, \\ k} - S_{i, \\ k })\n",
    "$$\n",
    "\n",
    "To make it a little bit easier to implement in Python using NumPy, we have the final math solution to the derivative of the Softmax function's outputs with respect to each of its inputs.\n",
    "\n",
    "$$\n",
    "\\frac{∂ S_{i, \\ j}}{∂z_{i, \\ k}}  = S_{i, \\ j} \\cdot ( \\delta _{j, \\ k} - S_{i, \\ k })\n",
    "= S_{i, \\ j} \\delta _{j, \\ k} - S_{i, \\ j}  S_{i, \\ k }\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba42c17",
   "metadata": {},
   "source": [
    "\n",
    "## 9.9. Softmax activation derivative code implementation\n",
    "\n",
    "We can code the solution using just two NumPy functions.\n",
    "\n",
    "In our case, the Jacobian matrix is an array of partial derivatives in all of the combinations of both input vectors.\n",
    "\n",
    "In section 9.8, we calculate the partial derivatives of every output of the Softmax function w.r.t each input separately, as each input influences each output due to the normalization process, which takes the sum of all the exponentiated inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7e77e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.21 -0.07 -0.14]\n",
      " [-0.07  0.09 -0.02]\n",
      " [-0.14 -0.02  0.16]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "softmax_output = [0.7, 0.1, 0.2]\n",
    "softmax_output = np.array(softmax_output).reshape(-1, 1)\n",
    "\n",
    "# First terms\n",
    "S_ijd_jk = softmax_output * np.eye(softmax_output.shape[0])\n",
    "S_ijd_jk = np.diagflat(softmax_output)\n",
    "\n",
    "# Second terms\n",
    "S_ijS_ik = np.dot(softmax_output, softmax_output.T)\n",
    "\n",
    "# The Jacobian matrix\n",
    "d_Sij_d_zik = S_ijd_jk - S_ijS_ik\n",
    "print(d_Sij_d_zik)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a741675",
   "metadata": {},
   "source": [
    "On a batch of samples, this operation returns a list if the Jacobian matrices, which forms a 3D matrix. We can visualize it as a column whose levels are Jacobian matrices being the sample-wise gradient of the Softmax function.\n",
    "\n",
    "This raises a question — if sample-wise gradients are the Jacobian matrices, how do we perform the chain rule with the gradient back-propagated from the loss function, since it’s a vector for each sample? Also, what do we do with the fact that the previous layer, which is the Dense layer, will expect the gradients to be a 2D array? Currently, we have a 3D array of the partial derivatives — a list of the Jacobian matrices. The derivative of the Softmax function with respect to any of its inputs returns a vector of partial derivatives (a row from the Jacobian matrix), as this input influences all the outputs, thus also influencing the partial derivative for each of them. We need to sum the values from these vectors so that each of the inputs for each of the samples will return a single partial derivative value instead. Because each input influences all of the outputs, the returned vector of the partial derivatives has to be summed up for the final partial derivative with respect to this input. We can perform this operation on each of the Jacobian matrices directly, applying the chain rule at the same time (applying the gradient from the loss function) using `np.dot()` — For each sample, it’ll take the row from the Jacobian matrix and multiply it by the corresponding value from the loss function’s gradient. As a result, the dot product of each of these vectors and values will return a singular value, forming a vector of the partial derivatives sample-wise and a 2D array (a list of the resulting vectors) batch-wise.\n",
    "\n",
    "Let’s code the solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47e2ac24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax activation\n",
    "class Activation_Softmax:\n",
    "    \n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        # Get unnormalized probabilities\n",
    "        exp_values = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n",
    "        \n",
    "        # Normalize them for each sample\n",
    "        probabilities = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
    "        self.output = probabilities\n",
    "        \n",
    "        \n",
    "    # Backward pass\n",
    "    def backward(self, dvalues):\n",
    "\n",
    "        # Create uninitialized array\n",
    "        self.dinputs = np.empty_like(dvalues)\n",
    "\n",
    "        # Enumerate outputs and gradients\n",
    "        for index, (single_output, single_dvalues) in enumerate (zip(self.output, dvalues)):\n",
    "            \n",
    "            # Flatten output array\n",
    "            single_output = single_output.reshape(-1, 1)\n",
    "\n",
    "            # Calculate Jacobian matrix of the output\n",
    "            jacobian_matrix = np.diagflat(single_output) - np.dot(single_output, single_output.T)\n",
    "\n",
    "            # Calculate sample-wise gradient and add it to the array of sample gradients\n",
    "            self.dinputs[index] = np.dot(jacobian_matrix, single_dvalues)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c49a6bc",
   "metadata": {},
   "source": [
    "## 9.10. Common Categorical Cross-Entropy loss and Softmax activation derivative\n",
    "\n",
    "We already calculated the partial derivatives of the Categorial Cross-Entropy loss and Softmax activation functions.\n",
    "\n",
    "Apply the chain rule to calculate the partial derivative of the Categorical Cross-Entropy loss function w.r.t the Softmax function inputs.\n",
    "\n",
    "Note that the inputs to the loss function $\\hat{y}_{ i, \\ j}$ are the outputs of the activation function $S_{i, \\ j}$:\n",
    "\n",
    "$$\n",
    "\\hat{y}_{ i, \\ j} = S_{i, \\ j}\n",
    "$$\n",
    "\n",
    "Let's define this derivative by applying the chain rule:\n",
    "\n",
    "$$\n",
    "\\frac{∂ L_i }{∂z_{i, \\ k}}  = \\frac{∂ L_i }{∂ \\hat{y}_{i, \\ j}}  \\cdot \\frac{∂ S_{i, \\ j}}{∂z_{i, \\ k}} = \\frac{∂ L_i }{∂ \\hat{y}_{i, \\ j}}  \\cdot \\frac{∂ \\hat{y}_{i, \\ j}}{∂ z_{i, \\ k}} =  - \\sum_j \\frac{y_{i, \\ j}}{\\hat{y}_{i, \\ j}} \\cdot \\frac{ ∂ \\hat{y}_{i, \\ j}  }{ ∂ z_{i, \\ k} }\n",
    "$$\n",
    "\n",
    "Recall from section 9.8, the derivative of the Softmax function with respect to its inputs is:\n",
    "\n",
    "$$\n",
    "\\frac{∂ S_{i,j}}{∂z_{i, \\ k}}  =\n",
    "\\begin{cases}\n",
    "S_{i, \\ j} \\cdot ( 1 - S_{i, \\ k})  , & j = k \\\\\n",
    "- S_{i, \\ j } \\cdot S_{i, \\ k }, & j ≠ k\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Let's substitute $S_{i, \\ j }$ with $\\hat{y}_{i, \\ j}$ we have:\n",
    "\n",
    "$$\n",
    "\\frac{∂ \\hat{y}_{i,j}}{∂z_{i, \\ k}}  =\n",
    "\\begin{cases}\n",
    "\\hat{y}_{i, \\ j} \\cdot ( 1 - \\hat{y}_{i, \\ k})  , & j = k \\\\\n",
    "- \\hat{y}_{i, \\ j } \\cdot \\hat{y}_{i, \\ k }, & j ≠ k\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "We have to split the current partial derivative following these cases (when $j=k$ and $j \\neq k$):\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{∂ L_i }{∂z_{i, \\ k}}  & = - \\sum_j \\frac{y_{i, \\ j}}{\\hat{y}_{i, \\ j}} \\cdot \\frac{ ∂ \\hat{y}_{i, \\ j}  }{ ∂ z_{i, \\ k}  } \\\\\n",
    "& = - \\frac{y_{i, \\ k}}{\\hat{y}_{i, \\ k}} \\cdot \\frac{ ∂ \\hat{y}_{i, \\ k}  }{ ∂ z_{i, \\ k}  } - \\sum_{j ≠ k} \\frac{y_{i, \\ j}}{\\hat{y}_{i, \\ j}} \\cdot \\frac{ ∂ \\hat{y}_{i, \\ j}  }{ ∂ z_{i, \\ k}  } \\\\\n",
    "& =  - \\frac{y_{i, \\ k}}{\\hat{y}_{i, \\ k}} \\cdot \\hat{y}_{i, \\ k} \\cdot (1- \\hat{y}_{i, \\ k}) - \\sum_{j ≠ k} \\frac{y_{i, \\ j}}{\\hat{y}_{i, \\ j}} ( - \\hat{y}_{i, \\ j} \\ \\hat{y}_{i, \\ k}) \\\\\n",
    "& = - y_{i, \\ k} \\cdot (1- \\hat{y}_{i, \\ k}) + \\sum_{j ≠ k} y_{i, \\ j} \\ \\hat{y}_{i, \\ k} \\\\\n",
    "& = - y_{i, \\ k} + y_{i, \\ k} \\ \\hat{y}_{i, \\ k} + \\sum_{j ≠ k} y_{i, \\ j} \\ \\hat{y}_{i, \\ k} \\\\\n",
    "& = - y_{i, \\ k} + \\sum_{j} y_{i, \\ j} \\ \\hat{y}_{i, \\ k} \\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Now the sum operator iterates over all of the possible values of $j$ and, since we know that $y_{i, \\ j}$ for each $i$ is the one-hot encoded vector of ground-truth values, the sum of all of its elements equas 1.\n",
    "\n",
    "In other words, this sum will multiply $0$ by the $\\hat{y}_{i, \\ k}$ except for a single situation, the true label, where it'll muliply $1$ by this value.\n",
    "\n",
    "Thus, we can further simplify:\n",
    "\n",
    "$$\n",
    "\\frac{∂ L_i}{∂ \\hat{y}_{i,j}} = - y_{i, \\ k} + \\sum_{j} y_{i, \\ j} \\ \\hat{y}_{i, \\ k} = - y_{i, \\ k} + \\hat{y}_{i, \\ k}  = \\hat{y}_{i, \\ k}  - y_{i, \\ k} \\\n",
    "$$\n",
    "\n",
    "Full solution:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{∂ L_i}{∂ \\hat{y}_{i,j}} &  = \\frac{∂ }{∂ \\hat{y}_{i,j}} \\Big[  - \\sum_j y_{i,j} \\ \\text{log} \\ \\big(  \\hat{y}_{i,j} \\big)  \\Big] = \\frac{∂ L_i }{∂ \\hat{y}_{i, \\ j}}  \\cdot \\frac{∂ \\hat{y}_{i, \\ j}}{∂ z_{i, \\ k}} \\\\\n",
    "& = - \\sum_j \\frac{y_{i, \\ j}}{\\hat{y}_{i, \\ j}} \\cdot \\frac{ ∂ \\hat{y}_{i, \\ j}  }{ ∂ z_{i, \\ k}  } = - \\frac{y_{i, \\ k}}{\\hat{y}_{i, \\ k}} \\cdot \\frac{ ∂ \\hat{y}_{i, \\ k}  }{ ∂ z_{i, \\ k}  } - \\sum_{j ≠ k} \\frac{y_{i, \\ j}}{\\hat{y}_{i, \\ j}} \\cdot \\frac{ ∂ \\hat{y}_{i, \\ j}  }{ ∂ z_{i, \\ k}  } \\\\\n",
    "& = - \\frac{y_{i, \\ k}}{\\hat{y}_{i, \\ k}} \\cdot \\hat{y}_{i, \\ k} \\cdot (1- \\hat{y}_{i, \\ k}) - \n",
    "\\sum_{j ≠ k} \\frac{y_{i, \\ j}}{\\hat{y}_{i, \\ j}} ( - \\hat{y}_{i, \\ j} \\ \\hat{y}_{i, \\ k}) = - y_{i, \\ k} \\cdot (1- \\hat{y}_{i, \\ k}) + \\sum_{j ≠ k} y_{i, \\ j} \\ \\hat{y}_{i, \\ k} \\\\\n",
    "& = - y_{i, \\ k} + y_{i, \\ k} \\ \\hat{y}_{i, \\ k}) + \\sum_{j ≠ k} y_{i, \\ j} \\ \\hat{y}_{i, \\ k}  =  - y_{i, \\ k} + \\sum_{j} y_{i, \\ j} \\ \\hat{y}_{i, \\ k}  \\\\\n",
    "& = - y_{i, \\ k} + \\hat{y}_{i, \\ k}  = \\hat{y}_{i, \\ k}  - y_{i, \\ k} \\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "We can see that, when we apply the chain rule to both partial derivatives, the whole equation simplifies significantly to the subtraction of the predicted and ground truth values. It is also multiple times faster to compute."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b29514",
   "metadata": {},
   "source": [
    "## 9.11. Common Categorical Cross-Entropy loss and Softmax activation derivative - code implementation\n",
    "\n",
    "No changes in the forward pass - we still need to perform it on the activation function to receive the outputs and then on the loss function to calculate the loss value.\n",
    "\n",
    "We'll code the solution as a separate class, which initializes both the Softmax activation and the Categorical Cross-Entropy objects, calling their forward methods respectively during the forward pass.\n",
    "\n",
    "For backpropagation, we create the backward step to calculates the combined gradient of the loss and activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0060b0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax classifier - combined Softmax activation and cross-entropy loss for faster backward step\n",
    "class Activation_Softmax_Loss_CategoricalCrossentropy():\n",
    "\n",
    "    # Creates activation and loss function objects\n",
    "    def __init__ ( self ):\n",
    "        self.activation = Activation_Softmax()\n",
    "        self.loss = Loss_CategoricalCrossentropy()\n",
    "\n",
    "    # Forward pass\n",
    "    def forward ( self , inputs , y_true ):\n",
    "        # Output layer's activation function\n",
    "        self.activation.forward(inputs)\n",
    "\n",
    "        # Set the output\n",
    "        self.output = self.activation.output\n",
    "\n",
    "        # Calculate and return loss value\n",
    "        return self.loss.calculate(self.output, y_true)\n",
    "\n",
    "    # Backward pass\n",
    "    def backward ( self , dvalues , y_true ):\n",
    "        # Number of samples\n",
    "        samples = len(dvalues)\n",
    "\n",
    "        # If labels are one-hot encoded, turn them into discrete values\n",
    "        if len (y_true.shape) == 2 :\n",
    "            y_true = np.argmax(y_true, axis = 1 )\n",
    "\n",
    "        # Copy so we can safely modify\n",
    "        self.dinputs = dvalues.copy()\n",
    "        \n",
    "        # Calculate gradient\n",
    "        self.dinputs[range(samples), y_true] -= 1\n",
    "        \n",
    "        # Normalize gradient\n",
    "        self.dinputs = self.dinputs / samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c50c7a0",
   "metadata": {},
   "source": [
    "## 9.12. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "47aab3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common loss class\n",
    "class Loss :\n",
    "    \n",
    "    # Calculates the data and regularization losses given model output and ground truth values\n",
    "    def calculate ( self , output , y ):\n",
    "        \n",
    "        # Calculate sample losses\n",
    "        sample_losses = self.forward(output, y)\n",
    "        \n",
    "        # Calculate mean loss\n",
    "        data_loss = np.mean(sample_losses)\n",
    "        \n",
    "        # Return loss\n",
    "        \n",
    "        return data_loss\n",
    "\n",
    "\n",
    "    \n",
    "# Softmax activation\n",
    "class Activation_Softmax:\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        # Remember input values\n",
    "        self.inputs = inputs\n",
    "\n",
    "        # Get unnormalized probabilities\n",
    "        exp_values = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n",
    "        \n",
    "        # Normalize them for each sample\n",
    "        probabilities = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
    "        self.output = probabilities\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues):\n",
    "        \n",
    "        # Create uninitialized array\n",
    "        self.dinputs = np.empty_like(dvalues)\n",
    "\n",
    "        # Enumerate outputs and gradients\n",
    "        for index, (single_output, single_dvalues) in enumerate(zip(self.output, dvalues)):\n",
    "            \n",
    "            # Flatten output array\n",
    "            single_output = single_output.reshape(-1, 1)\n",
    "            \n",
    "            # Calculate Jacobian matrix of the output\n",
    "            jacobian_matrix = np.diagflat(single_output) - np.dot(single_output, single_output.T)\n",
    "\n",
    "            # Calculate sample-wise gradient and add it to the array of sample gradients\n",
    "            self.dinputs[index] = np.dot(jacobian_matrix, single_dvalues)\n",
    "\n",
    "\n",
    "            \n",
    "# Cross-entropy loss\n",
    "class Loss_CategoricalCrossentropy(Loss):\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, y_pred, y_true):\n",
    "\n",
    "        # Number of samples in a batch\n",
    "        samples = len(y_pred)\n",
    "\n",
    "        # Clip data to prevent division by 0\n",
    "        # Clip both sides to not drag mean towards any value\n",
    "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "\n",
    "        # Probabilities for target values - only if categorical labels\n",
    "        if len(y_true.shape) == 1:\n",
    "            correct_confidences = y_pred_clipped[range(samples), y_true]\n",
    "\n",
    "        # Mask values - only for one-hot encoded labels\n",
    "        elif len(y_true.shape) == 2:\n",
    "            correct_confidences = np.sum(y_pred_clipped * y_true, axis=1)\n",
    "\n",
    "        # Losses\n",
    "        negative_log_likelihoods = -np.log(correct_confidences)\n",
    "        return negative_log_likelihoods\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues, y_true):\n",
    "\n",
    "        # Number of samples\n",
    "        samples = len(dvalues)\n",
    "        \n",
    "        # Number of labels in every sample\n",
    "        # We'll use the first sample to count them\n",
    "        labels = len(dvalues[0])\n",
    "\n",
    "        # If labels are sparse, turn them into one-hot vector\n",
    "        if len(y_true.shape) == 1:\n",
    "            y_true = np.eye(labels)[y_true]\n",
    "\n",
    "        # Calculate gradient\n",
    "        self.dinputs = -y_true / dvalues\n",
    "        \n",
    "        # Normalize gradient\n",
    "        self.dinputs = self.dinputs / samples\n",
    "\n",
    "        \n",
    "        \n",
    "# Softmax classifier - combined Softmax activation and cross-entropy loss for faster backward step\n",
    "class Activation_Softmax_Loss_CategoricalCrossentropy():\n",
    "\n",
    "    # Creates activation and loss function objects\n",
    "    def __init__(self):\n",
    "        self.activation = Activation_Softmax()\n",
    "        self.loss = Loss_CategoricalCrossentropy()\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, inputs, y_true):\n",
    "        # Output layer's activation function\n",
    "        self.activation.forward(inputs)\n",
    "        \n",
    "        # Set the output\n",
    "        self.output = self.activation.output\n",
    "        \n",
    "        # Calculate and return loss value\n",
    "        return self.loss.calculate(self.output, y_true)\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues, y_true):\n",
    "\n",
    "        # Number of samples\n",
    "        samples = len(dvalues)\n",
    "\n",
    "        # If labels are one-hot encoded, turn them into discrete values\n",
    "        if len(y_true.shape) == 2:\n",
    "            y_true = np.argmax(y_true, axis=1)\n",
    "\n",
    "        # Copy so we can safely modify\n",
    "        self.dinputs = dvalues.copy()\n",
    "        \n",
    "        # Calculate gradient\n",
    "        self.dinputs[range(samples), y_true] -= 1\n",
    "        \n",
    "        # Normalize gradient\n",
    "        self.dinputs = self.dinputs / samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187c5f33",
   "metadata": {},
   "source": [
    "Let's make up an output of the Softmax function and some target values.\n",
    "\n",
    "Next, backpropagate them using both solutions (the combined backward, through both of the functions separately) to test that they should return the same values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "924b8f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradients: combined loss and activation:\n",
      "[[-0.1         0.03333333  0.06666667]\n",
      " [ 0.03333333 -0.16666667  0.13333333]\n",
      " [ 0.00666667 -0.03333333  0.02666667]]\n",
      "Gradients: separate loss and activation:\n",
      "[[-0.09999999  0.03333334  0.06666667]\n",
      " [ 0.03333334 -0.16666667  0.13333334]\n",
      " [ 0.00666667 -0.03333333  0.02666667]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nnfs\n",
    "\n",
    "nnfs.init()\n",
    "\n",
    "softmax_outputs = np.array([[ 0.7 , 0.1 , 0.2 ],\n",
    "                            [ 0.1 , 0.5 , 0.4 ],\n",
    "                            [ 0.02 , 0.9 , 0.08 ]])\n",
    "class_targets = np.array([ 0 , 1 , 1 ])\n",
    "\n",
    "# Combined method\n",
    "softmax_loss = Activation_Softmax_Loss_CategoricalCrossentropy()\n",
    "softmax_loss.backward(softmax_outputs, class_targets)\n",
    "dvalues1 = softmax_loss.dinputs\n",
    "\n",
    "# Separate method\n",
    "activation = Activation_Softmax()\n",
    "activation.output = softmax_outputs\n",
    "loss = Loss_CategoricalCrossentropy()\n",
    "loss.backward(softmax_outputs, class_targets)\n",
    "activation.backward(loss.dinputs)\n",
    "dvalues2 = activation.dinputs\n",
    "\n",
    "print ( 'Gradients: combined loss and activation:' )\n",
    "print (dvalues1)\n",
    "print ( 'Gradients: separate loss and activation:' )\n",
    "print (dvalues2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a74937",
   "metadata": {},
   "source": [
    "The results are the same.\n",
    "\n",
    "The small difference between values in both arrays results from the precision of floating-point values in raw Python and NumPy.\n",
    "\n",
    "Let's compare the execution time of both methods by running both solutions multiple times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "95374785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.83564665840625\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from timeit import timeit\n",
    "import nnfs\n",
    "\n",
    "nnfs.init()\n",
    "\n",
    "softmax_outputs = np.array([[ 0.7 , 0.1 , 0.2 ],\n",
    "                            [ 0.1 , 0.5 , 0.4 ],\n",
    "                            [ 0.02 , 0.9 , 0.08 ]])\n",
    "\n",
    "class_targets = np.array([ 0 , 1 , 1 ])\n",
    "\n",
    "def f1 ():\n",
    "    softmax_loss = Activation_Softmax_Loss_CategoricalCrossentropy()\n",
    "    softmax_loss.backward(softmax_outputs, class_targets)\n",
    "    dvalues1 = softmax_loss.dinputs\n",
    "\n",
    "def f2 ():\n",
    "    activation = Activation_Softmax()\n",
    "    activation.output = softmax_outputs\n",
    "    loss = Loss_CategoricalCrossentropy()\n",
    "    loss.backward(softmax_outputs, class_targets)\n",
    "    activation.backward(loss.dinputs)\n",
    "    dvalues2 = activation.dinputs\n",
    "\n",
    "t1 = timeit( lambda : f1(), number = 10000 )\n",
    "t2 = timeit( lambda : f2(), number = 10000 )\n",
    "print (t2 / t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ceb17b5",
   "metadata": {},
   "source": [
    "Calculating the gradients separately is about 7 times slower, this factor can differ from a machine to a machine.\n",
    "\n",
    "So, it is worth putting in additional effort to calculate and code the optimized solution of the combined loss and activation function derivative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6268ef5",
   "metadata": {},
   "source": [
    "## 9.13. Full model code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f7ab814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.33333334 0.33333334 0.33333334]\n",
      " [0.3333332  0.3333332  0.33333364]\n",
      " [0.3333329  0.33333293 0.3333342 ]\n",
      " [0.3333326  0.33333263 0.33333477]\n",
      " [0.33333233 0.3333324  0.33333528]]\n",
      "loss: 1.0986104\n",
      "acc: 0.34\n",
      "[[ 1.5766357e-04  7.8368583e-05  4.7324400e-05]\n",
      " [ 1.8161038e-04  1.1045573e-05 -3.3096312e-05]]\n",
      "[[-3.60553473e-04  9.66117223e-05 -1.03671395e-04]]\n",
      "[[ 5.44109462e-05  1.07411419e-04 -1.61822361e-04]\n",
      " [-4.07913431e-05 -7.16780924e-05  1.12469446e-04]\n",
      " [-5.30112993e-05  8.58172934e-05 -3.28059905e-05]]\n",
      "[[-1.0729185e-05 -9.4610732e-06  2.0027859e-05]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nnfs\n",
    "from nnfs.datasets import spiral_data\n",
    "\n",
    "nnfs.init()\n",
    "\n",
    "\n",
    "# Dense layer\n",
    "class Layer_Dense:\n",
    "\n",
    "    # Layer initialization\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        # Initialize weights and biases\n",
    "        self.weights = 0.01 * np.random.randn(n_inputs, n_neurons)\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "        # Remember input values\n",
    "        self.inputs = inputs\n",
    "        # Calculate output values from inputs, weights and biases\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues):\n",
    "        # Gradients on parameters\n",
    "        self.dweights = np.dot(self.inputs.T, dvalues)\n",
    "        self.dbiases = np.sum(dvalues, axis=0, keepdims=True)\n",
    "        # Gradient on values\n",
    "        self.dinputs = np.dot(dvalues, self.weights.T)\n",
    "\n",
    "\n",
    "# ReLU activation\n",
    "class Activation_ReLU:\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        # Remember input values\n",
    "        self.inputs = inputs\n",
    "        # Calculate output values from inputs\n",
    "        self.output = np.maximum(0, inputs)\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues):\n",
    "        # Since we need to modify original variable,\n",
    "        # let's make a copy of values first\n",
    "        self.dinputs = dvalues.copy()\n",
    "\n",
    "        # Zero gradient where input values were negative\n",
    "        self.dinputs[self.inputs <= 0] = 0\n",
    "\n",
    "\n",
    "# Softmax activation\n",
    "class Activation_Softmax:\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "        # Remember input values\n",
    "        self.inputs = inputs\n",
    "\n",
    "        # Get unnormalized probabilities\n",
    "        exp_values = np.exp(inputs - np.max(inputs, axis=1,\n",
    "                                            keepdims=True))\n",
    "        # Normalize them for each sample\n",
    "        probabilities = exp_values / np.sum(exp_values, axis=1,\n",
    "                                            keepdims=True)\n",
    "\n",
    "        self.output = probabilities\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues):\n",
    "\n",
    "        # Create uninitialized array\n",
    "        self.dinputs = np.empty_like(dvalues)\n",
    "\n",
    "        # Enumerate outputs and gradients\n",
    "        for index, (single_output, single_dvalues) in \\\n",
    "                enumerate(zip(self.output, dvalues)):\n",
    "            # Flatten output array\n",
    "            single_output = single_output.reshape(-1, 1)\n",
    "            # Calculate Jacobian matrix of the output\n",
    "            jacobian_matrix = np.diagflat(single_output) - \\\n",
    "                              np.dot(single_output, single_output.T)\n",
    "\n",
    "            # Calculate sample-wise gradient\n",
    "            # and add it to the array of sample gradients\n",
    "            self.dinputs[index] = np.dot(jacobian_matrix,\n",
    "                                         single_dvalues)\n",
    "\n",
    "\n",
    "# Common loss class\n",
    "class Loss:\n",
    "\n",
    "    # Calculates the data and regularization losses\n",
    "    # given model output and ground truth values\n",
    "    def calculate(self, output, y):\n",
    "\n",
    "        # Calculate sample losses\n",
    "        sample_losses = self.forward(output, y)\n",
    "\n",
    "        # Calculate mean loss\n",
    "        data_loss = np.mean(sample_losses)\n",
    "\n",
    "        # Return loss\n",
    "        return data_loss\n",
    "\n",
    "\n",
    "# Cross-entropy loss\n",
    "class Loss_CategoricalCrossentropy(Loss):\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, y_pred, y_true):\n",
    "\n",
    "        # Number of samples in a batch\n",
    "        samples = len(y_pred)\n",
    "\n",
    "        # Clip data to prevent division by 0\n",
    "        # Clip both sides to not drag mean towards any value\n",
    "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "\n",
    "        # Probabilities for target values -\n",
    "        # only if categorical labels\n",
    "        if len(y_true.shape) == 1:\n",
    "            correct_confidences = y_pred_clipped[\n",
    "                range(samples),\n",
    "                y_true\n",
    "            ]\n",
    "\n",
    "\n",
    "        # Mask values - only for one-hot encoded labels\n",
    "        elif len(y_true.shape) == 2:\n",
    "            correct_confidences = np.sum(\n",
    "                y_pred_clipped * y_true,\n",
    "                axis=1\n",
    "            )\n",
    "\n",
    "        # Losses\n",
    "        negative_log_likelihoods = -np.log(correct_confidences)\n",
    "        return negative_log_likelihoods\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues, y_true):\n",
    "\n",
    "        # Number of samples\n",
    "        samples = len(dvalues)\n",
    "        # Number of labels in every sample\n",
    "        # We'll use the first sample to count them\n",
    "        labels = len(dvalues[0])\n",
    "\n",
    "        # If labels are sparse, turn them into one-hot vector\n",
    "        if len(y_true.shape) == 1:\n",
    "            y_true = np.eye(labels)[y_true]\n",
    "\n",
    "        # Calculate gradient\n",
    "        self.dinputs = -y_true / dvalues\n",
    "        # Normalize gradient\n",
    "        self.dinputs = self.dinputs / samples\n",
    "\n",
    "\n",
    "# Softmax classifier - combined Softmax activation\n",
    "# and cross-entropy loss for faster backward step\n",
    "class Activation_Softmax_Loss_CategoricalCrossentropy():\n",
    "\n",
    "    # Creates activation and loss function objects\n",
    "    def __init__(self):\n",
    "        self.activation = Activation_Softmax()\n",
    "        self.loss = Loss_CategoricalCrossentropy()\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, inputs, y_true):\n",
    "        # Output layer's activation function\n",
    "        self.activation.forward(inputs)\n",
    "        # Set the output\n",
    "        self.output = self.activation.output\n",
    "        # Calculate and return loss value\n",
    "        return self.loss.calculate(self.output, y_true)\n",
    "\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues, y_true):\n",
    "\n",
    "        # Number of samples\n",
    "        samples = len(dvalues)\n",
    "\n",
    "        # If labels are one-hot encoded,\n",
    "        # turn them into discrete values\n",
    "        if len(y_true.shape) == 2:\n",
    "            y_true = np.argmax(y_true, axis=1)\n",
    "\n",
    "        # Copy so we can safely modify\n",
    "        self.dinputs = dvalues.copy()\n",
    "        # Calculate gradient\n",
    "        self.dinputs[range(samples), y_true] -= 1\n",
    "        # Normalize gradient\n",
    "        self.dinputs = self.dinputs / samples\n",
    "\n",
    "\n",
    "# Create dataset\n",
    "X, y = spiral_data(samples=100, classes=3)\n",
    "\n",
    "# Create Dense layer with 2 input features and 3 output values\n",
    "dense1 = Layer_Dense(2, 3)\n",
    "\n",
    "# Create ReLU activation (to be used with Dense layer):\n",
    "activation1 = Activation_ReLU()\n",
    "\n",
    "# Create second Dense layer with 3 input features (as we take output\n",
    "# of previous layer here) and 3 output values (output values)\n",
    "dense2 = Layer_Dense(3, 3)\n",
    "\n",
    "# Create Softmax classifier's combined loss and activation\n",
    "loss_activation = Activation_Softmax_Loss_CategoricalCrossentropy()\n",
    "\n",
    "# Perform a forward pass of our training data through this layer\n",
    "dense1.forward(X)\n",
    "\n",
    "# Perform a forward pass through activation function\n",
    "# takes the output of first dense layer here\n",
    "activation1.forward(dense1.output)\n",
    "\n",
    "# Perform a forward pass through second Dense layer\n",
    "# takes outputs of activation function of first layer as inputs\n",
    "dense2.forward(activation1.output)\n",
    "\n",
    "# Perform a forward pass through the activation/loss function\n",
    "# takes the output of second dense layer here and returns loss\n",
    "loss = loss_activation.forward(dense2.output, y)\n",
    "# Let's see output of the first few samples:\n",
    "print(loss_activation.output[:5])\n",
    "\n",
    "# Print loss value\n",
    "print('loss:', loss)\n",
    "\n",
    "# Calculate accuracy from output of activation2 and targets\n",
    "# calculate values along first axis\n",
    "predictions = np.argmax(loss_activation.output, axis=1)\n",
    "if len(y.shape) == 2:\n",
    "    y = np.argmax(y, axis=1)\n",
    "accuracy = np.mean(predictions==y)\n",
    "\n",
    "# Print accuracy\n",
    "print('acc:', accuracy)\n",
    "\n",
    "# Backward pass\n",
    "loss_activation.backward(loss_activation.output, y)\n",
    "dense2.backward(loss_activation.dinputs)\n",
    "activation1.backward(dense2.dinputs)\n",
    "dense1.backward(activation1.dinputs)\n",
    "\n",
    "# Print gradients\n",
    "print(dense1.dweights)\n",
    "print(dense1.dbiases)\n",
    "print(dense2.dweights)\n",
    "print(dense2.dbiases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f212cf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnfs",
   "language": "python",
   "name": "nnfs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
